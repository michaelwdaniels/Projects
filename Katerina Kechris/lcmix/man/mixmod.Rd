\name{mixmod}

\alias{mixmod}
\alias{print.mixmod}

\concept{parameter estimation}
\concept{maximum likelihood estimation}
\concept{maximum likelihood estimator}
\concept{mixture model estimation}
\concept{EM algorithm}
\concept{expectation maximization algorithm}

\title{
Single Data Source Mixture Model
}

\description{
Fit a finite mixture model to a single source of data using one of several distributions.
}

\usage{
mixmod(X, K, family=names(LC_FAMILY), prior=NULL, iter.max=LC_ITER_MAX, 
    dname=deparse(substitute(X)))
\method{print}{mixmod}(x, ...)
}

\arguments{
\item{X}{for univariate data, a vector; for multivariate data, a matrix or data frame.  Must consist only of numeric values.  Each element of the vector, or each row of the matrix or data frame, should represent an independent observation.}
\item{K}{the number of components, an integer greater than or equal to 1.  \code{K=1} will result in the distribution specified by \code{family} being fitted to the entire data set, and is not particularly useful.}
\item{family}{a string, one of the supported distribution family names given in \code{\link{LC_FAMILY}}.  By default, \code{"normal"} is used.  Partial matches are allowed.}
\item{prior}{prior probability distribution on \eqn{\mathcal Y}{Y}.  This feature is under development and its use is not currently recommended.}
\item{iter.max}{the maximum number of iterations for the EM algorithm, by default equal to \code{\link{LC_ITER_MAX}}.}
\item{dname}{the name of the data.}
\item{x}{an object of class \code{mixmod}.}
\item{...}{further arguments to \code{print.default}.}
}

\details{
In the finite mixture model used here, a hidden categorical random variable \eqn{\mathcal{Y}}{Y}, which can take on values from 1 to some positive integer \eqn{K}, generates the distribution of the observed random variable \eqn{\mathcal{X}}{X}, from which the observed \code{X} is assumed to be drawn.  
Specifically, \code{mixmod} fits a mixture model of the form

\deqn{f(x) = \sum_k p_k f_k(x)}{f(x) = sum_k p_k f_k(x)}

where \eqn{k = 1, \dots, K} and each \eqn{f_k(.)} is a density function on the sample space of \eqn{\mathcal{X}}{X}.  The \eqn{p_k}'s, that is, the component probabilities, sum to 1.

The EM algorithm used in model fitting attempts to maximize the Q-value, that is, the expected complete data log-likelihood, for the model.  The parameter values which maximize the Q-value also maximize the log-likelihood for the density given above.
}

\value{
A list of class \code{mixmod}, having the following elements:
\item{N}{the length of the data, that is, \code{length(X)} if \code{X} is a vector, or \code{nrow(X)} if \code{X} is a matrix or data frame.}
\item{D}{the width of the data, that is, 1 if \code{X} is a vector, or \code{ncol(X)} if \code{X} is a matrix or data frame.}
\item{K}{the number of components in the mixture model.}
\item{X}{the original data; if \code{X} was a data frame, it will have been converted to a matrix.}
\item{npar}{the total number of parameters in the model.}
\item{npar.hidden}{the number of parameters for the hidden component portion of the model.}
\item{npar.observed}{the number of parameters for the observed data portion of the model.}
\item{iter}{the number of iterations required to fit the model.}
\item{params}{the parameters estimated for the model.  This is a list with elements \code{hidden} and \code{observed}, corresponding to distribution for the hidden and observed portions of the model.  \code{hidden} always has one element, \code{prob}, the vector of \eqn{p_k}'s.  The elements of \code{observed} depend on the distribution family chosen in fitting the model.}
\item{stats}{a vector with named elements corresponding to the number of iterations, log-likelihood, Q-value, and BIC for the estimated parameters.}
\item{weights}{a list with the single element \code{W}, the \eqn{N \times K}{N-by-K} matrix of weights used in the M-step of the EM algorithm for estimating the final set of parameters for the observed data portion of the model.}
\item{pdfs}{a list with two elements:  \code{G}, the \eqn{N \times K}{N-by-K} matrix of which the \eqn{(n,k)}th element is the estimated value of \eqn{f_k(x_n)}, where \eqn{x_n} is the \eqn{n}th observation in \code{X}; and \code{fX}, the vector of length \code{N} of which the \eqn{n}th element is the estimated value of \eqn{f(x_n)}.}
\item{posterior}{the \eqn{N \times K}{N-by-K} matrix of which the \eqn{(n,k)}th element is the estimated posterior probability that the \eqn{n}th observation was generated by the \eqn{k}th component.  Equal to the \code{W} element of \code{weights}.}
\item{assignment}{the vector of length \eqn{N} of which the \eqn{n}th element is the most probable component to have generated the \eqn{n}th observation.  In other words, \code{assignment[n] = which.max(posterior[n,])}.}
\item{iteration.params}{a list of length \code{iter} giving the estimated parameters at each iteration of the algorithm.}
\item{iteration.stats}{a data frame of \code{iter} rows giving iteration statistics, as in \code{stats}, at each iteration of the algorithm.}
\item{family}{the name of the distribution family used in the model. See \code{\link{LC_FAMILY}}.}
\item{distn}{the name of the actual distribution used in the model. See \code{\link{LC_FAMILY}}.}
\item{prior}{the value of the \code{prior} parameter used in model fitting.  See Arguments.}
\item{iter.max}{the maximum number of distributions allowed in model fitting.}
\item{dname}{the name of the data.}
\item{dattr}{attributes of the data, used by model likelihood functions to determine if the data have been scaled or otherwise transformed.}
\item{kvec}{a vector of integers from 1 to \eqn{K}{K}.}
}

\references{
McLachlan, G.J. and Thriyambakam, K.  (2008)  \emph{The EM Algorithm and Extensions}, John Wiley & Sons.
}

\author{
Daniel Dvorkin
}

\seealso{
\code{\link{LC_FAMILY}} for distributions and families; \code{\link{mdmixmod}} for fitting multiple-data mixture models; \code{\link{reporting}} and \code{\link{likelihood}} for model reporting; \code{\link{rocinfo}} for performance evaluation; \code{convergencePlot} for behavior of the algorithm; \code{\link{simulation}} for simulating from the parameters of a model; packages \code{mixtools} and \code{mclust}.
}

\examples{\dontrun{ 
data(CiData)
data(CiGene)
fit <- mixmod(CiData$expression, 3)
fit
# Normal mixture model ('mvnorm')
# Data 'CiData$expression' of size 10244-by-4 fitted to 3 components
# Model statistics:
#       iter       llik       qval        bic     iclbic 
#      42.00  -47499.54  -50052.71  -95405.40 -100511.73
plot(rocinfo(fit, CiGene$target))
}}

\keyword{graphs}
\keyword{models}
\keyword{cluster}
\keyword{classif}
